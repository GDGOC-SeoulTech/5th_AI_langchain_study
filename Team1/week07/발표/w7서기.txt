week7 서기: 임가영
2026-01-04

1. 제미나이 같은 llm 서비스는 사용자가 입력하는 문서가 혹은 복붙하는 텍스트가 어떤 형식을 가진 문서(마크다운, 한글파일 등등)의 구조를 가지고 있는지 파악하고 splitter를 구분해서 사용하는거야?
- llm은 토큰의 나열로만 입력받아서 텍스트로만 주면 pdf에서 긁어온건지 markdown에서 긁어왔는지 판단하는게 아니라 
들어온 토큰들 사이의 관계와 패턴만 볼 뿐, 파일의 구조적인 형식을 스스로 확인하지 않습니다. 따라서 성능을 높이려면 개발자가 사전에 형식을 파악해 문서를 어떻게 쪼개서 넣어줄지 결정하는 전처리가 매우 중요합니다. 
우리가 사용하는 챗GPT 같은 '서비스'와 '모델' 자체의 동작을 구분해서 이해해야 합니다.

2. Semantic Chunking 코드에 70(백분위수) 자르는기준이 상위 70인지 하위 70인지
- 상위 70퍼센트 

3. 사용자가 질문할때 긴 텍스트를 넣으면 서비스 내에서 splitter가 적용이 되는지 알아봤습니다. (질문 아님)
-chatGPT는 길게 들어올때는 시스템 프롬프트 차원에서 요약을 먼저 하거나, 내부적으로 데이터를 분할해 처리하는 자체 Splitter 로직이 작동할 수 있다. Gemini 같은 다른 서비스는 웬만한 길이는 쪼개지 않고 통째로(Raw) 처리해 문맥 유지력을 극대화한다.

4. semantic chunker가 임계값에 따라 나눠진다고 했는네 처음에 그 임계값이 정해지는 기준이 뭔가요? percentile인지 아니면 s.d., IQR 등
- 문서의 분포 특성에 따라 다릅니다. 가장 보편적으로는 Percentile을 사용하여 상대적인 거리 차이로 자릅니다. 만약 갑자기 튀는 문장 같은 이상치가 많을 때는 IQR을 사용하여 안정적으로 경계를 잡고, 유사도 변화가 고를 때는 Standard Deviation(표준편차)을 기준으로 삼아 의미가 변하는 지점을 포착합니다.

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "왜 Reranker를 쓰나요? (주요 장점)\n",
        "- 정확도 향상: 단순 벡터 검색은 단어의 의미가 비슷하면 관련 없는 내용도 가져올 수 있는데, Reranker가 이를 걸러줍니다.\n",
        "\n",
        "- LLM 비용 절감: 연관성이 높은 상위 3~5개 문서만 LLM에 전달하므로, 불필요한 토큰 낭비를 줄이고 답변의 질을 높입니다.\n",
        "\n",
        "- Context Window 최적화: LLM이 한 번에 읽을 수 있는 양은 제한되어 있으므로, \"진짜 핵심\"만 전달하는 것이 유리합니다."
      ],
      "metadata": {
        "id": "0_Di4bVM9lrO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습 방법\n",
        "### 1. 포인트와이즈(Pointwise)\n",
        ": 개별 쿼리-문서 쌍의 관련성 점수 예측\n",
        "- 한 명씩 면접장에 들어오게 해서 절대평가로 점수를 매기는 것\n",
        "### 2. 페어와이즈(Pairwise)\n",
        ": 두 문서 간의 상대적 관련성 비교\n",
        "- 두 명을 동시에 불러서 토너먼트식 비교\n",
        "### 3. 리스트와이즈(Listwise)\n",
        ": 후보군에 있는 모든 문서(List)를 한꺼번에 모델에 넣고, 전체적인 최적의 순서를 한 번에 결정\n",
        "- 지원자 10명을 한 방에 넣고 1등부터 10등까지 전체 순위를 한 번에 매기는 것."
      ],
      "metadata": {
        "id": "NZLL4qcJSOdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문서 출력 도우미 함수\n",
        "def pretty_print_docs(docs):\n",
        "    print(\n",
        "        f\"\\n{'-' * 100}\\n\".join(\n",
        "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "CRkK2Ljl2ztU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain langchain-community langchain-text-splitters sentence-transformers langchain_huggingface faiss-cpu"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Bowfd8Wb4E1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt"
      ],
      "metadata": {
        "id": "IIKHdQoHee79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4가지 Reranker 라이브러리"
      ],
      "metadata": {
        "id": "5o-8wqEYTRb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01. Cross Encoder Reranker"
      ],
      "metadata": {
        "id": "o0NedZhuTSsU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "가장 근본적인 형태입니다. SentenceTransformers 라이브러리를 통해 직접 모델을 로드"
      ],
      "metadata": {
        "id": "cQg40cI-UVEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# 문서 로드\n",
        "documents = TextLoader(\"./data/appendix-keywords.txt\").load()\n",
        "\n",
        "# 텍스트 분할기 설정\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "\n",
        "# 문서 분할\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# 임베딩 모델 설정\n",
        "embeddingsModel = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/msmarco-distilbert-dot-v5\"\n",
        ")\n",
        "\n",
        "# 문서로부터 FAISS 인덱스 생성 및 검색기 설정\n",
        "retriever = FAISS.from_documents(texts, embeddingsModel).as_retriever(\n",
        "    search_kwargs={\"k\": 10}\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oxlGfRpf28GK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 질의 설정\n",
        "query = \"Word2Vec에 대해서 알려줄래?\"\n",
        "\n",
        "# 질의 수행 및 결과 문서 반환\n",
        "docs = retriever.invoke(query)\n",
        "\n",
        "# 결과 문서 출력\n",
        "pretty_print_docs(docs)"
      ],
      "metadata": {
        "id": "2kt_5R6CVst6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec은 Word Embedding의 한 종류이기에 결과가 이렇게 나온거임\n",
        "-> reranker 필요"
      ],
      "metadata": {
        "id": "FTtYx5dGUEc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ContextualCompressionRetriever ( Retriever + Reranker )"
      ],
      "metadata": {
        "id": "7GU3ejigVovx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
        "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
        "\n",
        "# 모델 초기화\n",
        "model = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-v2-m3\")\n",
        "\n",
        "# 상위 3개의 문서 선택\n",
        "compressor = CrossEncoderReranker(model=model, top_n=3)\n",
        "\n",
        "# 문서 압축 검색기 초기화\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=retriever\n",
        ")\n",
        "\n",
        "# 압축된 문서 검색\n",
        "compressed_docs = compression_retriever.invoke(\"Word2Vec 에 대해서 알려줄래?\")\n",
        "\n",
        "# 문서 출력\n",
        "pretty_print_docs(compressed_docs)\n"
      ],
      "metadata": {
        "id": "OxKhnBrGVYDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02. Cohere Reranker"
      ],
      "metadata": {
        "id": "WmpAp90qTYJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "유료 API 서비스입니다. 모델 내부를 볼 수는 없지만"
      ],
      "metadata": {
        "id": "Qz9xE4xkUQPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU cohere"
      ],
      "metadata": {
        "id": "TkDlZVJ4ToO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cohere API 키 발급 안함. 그리고 위 코드에서 아래쪽만 다름"
      ],
      "metadata": {
        "id": "FecfLyZtYilA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 검색기 초기화\n",
        "retriever = FAISS.from_documents(\n",
        "    texts, CohereEmbeddings(model=\"embed-multilingual-v3.0\")\n",
        ").as_retriever(search_kwargs={\"k\": 10})\n",
        "\n",
        "# 문서 검색\n",
        "docs = retriever.invoke(query)\n",
        "\n",
        "# 문서 출력\n",
        "pretty_print_docs(docs)"
      ],
      "metadata": {
        "id": "XxqsKyuqYiM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Cohere의 Retriever 성능이 워낙 좋아서 리랭커 없이도 충분한 품질이 나옴"
      ],
      "metadata": {
        "id": "AEuTbgHoa_l2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "reranker"
      ],
      "metadata": {
        "id": "cJ_THNaBaBTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "# 문서 재정렬 모델 설정\n",
        "compressor = CohereRerank(model=\"rerank-multilingual-v3.0\")\n",
        "\n",
        "# 문맥 압축 검색기 설정\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=retriever\n",
        ")\n",
        "\n",
        "# 압축된 문서 검색\n",
        "compressed_docs = compression_retriever.invoke(\"Word2Vec 에 대해서 알려줘!\")\n",
        "\n",
        "# 압축된 문서 출력\n",
        "pretty_print_docs(compressed_docs)\n"
      ],
      "metadata": {
        "id": "d4tccD0laAeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03. Jina Reranker"
      ],
      "metadata": {
        "id": "nXvUCQiaTazi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "긴 문장(8k 토큰 이상)을 처리하는 데 특화"
      ],
      "metadata": {
        "id": "l3K1OmgTUG_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# 문서 로드\n",
        "documents = TextLoader(\"./data/appendix-keywords.txt\").load()\n",
        "\n",
        "# 텍스트 분할기 초기화\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "\n",
        "# 문서 분할\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# 검색기 초기화\n",
        "retriever = FAISS.from_documents(\n",
        "    texts, OpenAIEmbeddings()\n",
        ").as_retriever(search_kwargs={\"k\": 10})\n",
        "\n",
        "# 질의문\n",
        "query = \"Word2Vec 에 대해서 설명해줘.\"\n",
        "\n",
        "# 문서 검색\n",
        "docs = retriever.invoke(query)\n",
        "\n",
        "# 문서 출력\n",
        "pretty_print_docs(docs)"
      ],
      "metadata": {
        "id": "wZIf4CgoToqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "reranker는 단독으로 동작하는 것이 아니라\n",
        "\n",
        "먼저 OpenAIEmbeddings 같은 모델로 후보군을 대충 추려낸 뒤(Retriever 단계), 그 후보들만 Jina Reranker에게 전달해 정밀 검사를 시키는 구조라서\n",
        "\n",
        "위 코드는 Jina Reranker를 적용하기 **'전'**의 상태를 보여줘 성능 차이를 보여주려는 의도!"
      ],
      "metadata": {
        "id": "rm_J5xWfcyyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import mod\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain_community.document_compressors import JinaRerank\n",
        "\n",
        "# JinaRerank 압축기 초기화\n",
        "compressor = JinaRerank(model=\"jina-reranker-v2-base-multilingual\", top_n=3)\n",
        "\n",
        "# 문서 압축 검색기 초기화\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=retriever\n",
        ")\n",
        "\n",
        "# 관련 문서 검색 및 압축\n",
        "compressed_docs = compression_retriever.invoke(\n",
        "    \"Word2Vec 에 대해서 설명해줘.\"\n",
        ")\n",
        "pretty_print_docs(compressed_docs)"
      ],
      "metadata": {
        "id": "IddKwwrndkuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04. FlashRank Reranker"
      ],
      "metadata": {
        "id": "0ImpJJttTeDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능보다 **'속도'**에 올인한 초경량 및 초고속 Python 라이브러리"
      ],
      "metadata": {
        "id": "GLH70JtcULIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU flashrank"
      ],
      "metadata": {
        "id": "8GlyvrJdUKx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# 문서 로드\n",
        "documents = TextLoader(\"./data/appendix-keywords.txt\").load()\n",
        "\n",
        "# 텍스트 분할기 초기화\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "\n",
        "# 문서 분할\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# 각 텍스트에 고유 ID 추가\n",
        "for idx, text in enumerate(texts):\n",
        "    text.metadata[\"id\"] = idx\n",
        "\n",
        "# 검색기 초기화\n",
        "retriever = FAISS.from_documents(\n",
        "    texts, OpenAIEmbeddings()\n",
        ").as_retriever(search_kwargs={\"k\": 10})\n",
        "\n",
        "# 질의문\n",
        "query = \"Word2Vec 에 대해서 설명해줘.\"\n",
        "\n",
        "# 문서 검색\n",
        "docs = retriever.invoke(query)\n",
        "\n",
        "# 문서 출력\n",
        "pretty_print_docs(docs)\n"
      ],
      "metadata": {
        "id": "wHUPrwP9TpWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q. 다른 reranker 설명 문서에서의 코드와 달리 각 텍스트에 고유 ID를 추가하는 이유가 뭘까?\n",
        "\n",
        "다른 Reranker들은 서버(cloud)형 서비스로, 문서를 보내면 서버 내부에서 알아서 인덱싱하고 처리한 뒤 결과를 돌려주니에 매핑 과정을 사용자가 신경 쓸 필요가 적지만\n",
        "\n",
        "flash는 local에서 직접 돌아가다보니 내부적으로 문서들을 빠르게 구분하고 정렬하기 위해 **\"숫자나 문자로 된 이름표(ID)\"**가 반드시 있어야만 작동하도록 설계되어있어 그렇게 한다."
      ],
      "metadata": {
        "id": "iHXc1HsmevdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import FlashrankRerank\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# LLM 초기화\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "# 문서 압축기 초기화\n",
        "compressor = FlashrankRerank(model=\"ms-marco-MultiBERT-L-12\")\n",
        "\n",
        "# 문맥 압축 검색기 초기화\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=retriever\n",
        ")\n",
        "\n",
        "# 압축된 문서 검색\n",
        "compressed_docs = compression_retriever.invoke(\n",
        "    \"Word2Vec 에 대해서 설명해줘.\"\n",
        ")\n",
        "\n",
        "# 문서 ID 출력\n",
        "print([doc.metadata[\"id\"] for doc in compressed_docs])"
      ],
      "metadata": {
        "id": "bTJRxlsaf6Hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FlashrankRerank가 재정렬한 결과, 질문에 가장 적합하다고 판단된 문서들의 원래 '이름표(ID)'가 출력됨"
      ],
      "metadata": {
        "id": "fWdYZvYwgXru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretty_print_docs(compressed_docs)"
      ],
      "metadata": {
        "id": "XVurtVktgBYk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}